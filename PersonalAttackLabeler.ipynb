{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Josh's attempt at an inclusive online-attack identifier\n",
    "   #### Overview:\n",
    "Using the dataset [Wikipedia Talk Labels: Personal Attacks](https://figshare.com/articles/Wikipedia_Talk_Labels_Personal_Attacks/4054689) I built a natural language processor to identify personal attacks in online comments and forum posts. In order to train a model that is more conscious of intersectionally unique voices and perceptions, especially from those who are systemically underrepresented in modern society, I incorporated the available demographics data in an attempt to promote these voices. The methods for doing so are explained in the textbox below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion \n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import SGDClassifier, RidgeClassifier\n",
    "from sklearn.feature_extraction import text \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Working With Data\n",
    "   #### 1.1 Combining the three sources:\n",
    "   In order to include minority opinions in the \"attack\" labled data, I discussed the data with several friends who together cover more than half of the demographic catagories in the dataset as well as 6 different ethnicities (best somewhat representative sample I could manage during COVID) before settling on the measures where:\n",
    "   \n",
    "   - Every comment marked an attack by 50% or more annotators would be labled as such.\n",
    "   \n",
    "   - Additionally, any comment where more than 50% of a given demographic claimed something was an attack that also had 25% agreement from annotators overall.\n",
    "   \n",
    "       - Greater than 50% of a demographic is required because no individual of a group is a monolith speaking for all of the group, so if there is equal consideration for and against, then it is likely some other factor driving their evaluations.\n",
    "       \n",
    "       - The 25% support overall requirement was chosen to ensure that at least one other annotator inside or outside of the demographic agreed. (the minimum number of annotators on a comment is 8)\n",
    "       \n",
    "           - Requiring someone else to agree was a response to the lack of quality in the demographic data which was only available for 54% of annotators.\n",
    "           \n",
    "           - The data also covered a rather limited range of demographics:\n",
    "           \n",
    "               - gender: Options were male, female, other but no annotator used other so this comlumn was expanded into male and female columns\n",
    "\n",
    "               - english as a first language: already a boolean column\n",
    "               \n",
    "               - age: Each age range was split into its own column\n",
    "               \n",
    "               - education: I reduce the responses into 2 buckets of no_degree and college_degree due to the lack of overall participation. The thought being that a college education's intent is to mold an individual's world views and thought processes so the split between holding a college degree vs. not would be most likely to produce different lived experiences and thus perceptions of what constitutes an attack.\n",
    "\n",
    "The demographic dataset is far from perfect and negatively contributed to model performance, which is covered in a later section. However, data is often less robust than would be preferred, so it is a constraint that will likely be a part of any ML project and therefore is useful to still attempt to utilize.\n",
    "\n",
    "NumPy/Pandas were utilized exclusively to avoid iterating through data during transformation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the three tsv documents\n",
    "comments = pd.read_csv('attack_annotated_comments.tsv', sep = '\\t', index_col = 0)\n",
    "annotations = pd.read_csv('attack_annotations.tsv',  sep = '\\t')\n",
    "demographics = pd.read_csv('attack_worker_demographics.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the demographic data to the annotations data, then blow it\n",
    "# out into boolean series (technically 1s and 0s) and drop any irrelevant or pre-blown-out columns\n",
    "annotWithDemo = pd.merge(annotations, demographics, on='worker_id', how='left')\n",
    "annotWithDemo.drop(columns=['quoting_attack','recipient_attack','third_party_attack',\n",
    "                            'other_attack', 'worker_id'], inplace=True)\n",
    "boolCols = annotWithDemo.join(annotWithDemo.gender.str.get_dummies())\n",
    "boolCols.drop(columns='gender',inplace=True)\n",
    "boolCols = boolCols.join(boolCols.age_group.str.get_dummies())\n",
    "boolCols.drop(columns='age_group',inplace=True)\n",
    "boolCols = boolCols.join(boolCols.education.str.get_dummies())\n",
    "boolCols.drop(columns='education',inplace=True)\n",
    "boolCols['no_degree'] = boolCols['none'] + boolCols['some'] + boolCols['hs']\n",
    "boolCols['college_degree'] = boolCols['bachelors'] + boolCols['doctorate'] + boolCols['masters'] + boolCols['professional']\n",
    "boolCols.drop(columns=['bachelors','doctorate','hs','masters','none','professional','some'],\n",
    "              inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame containing only reviews with at least one attack identified\n",
    "# Group both data frames by rev_id, the \"attack only\" frame will be used as the numerator in\n",
    "# finding pctg of each demographic column that labeled a review an attack\n",
    "boolColsAttackOnly = boolCols.loc[boolCols['attack'] > 0]\n",
    "boolColsAttackOnlyGrouped = boolColsAttackOnly.groupby('rev_id', as_index=False).sum()\n",
    "boolColsGrouped = boolCols.groupby('rev_id', as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the demographic columns into percentages and find the overall pct of\n",
    "# annotators marking a comment as an attack to aid in classifying comments\n",
    "allRev= boolColsGrouped['rev_id'].to_frame(\"rev_id\")\n",
    "allRevAttackOnlyGrouped = pd.merge(allRev, boolColsAttackOnlyGrouped, on='rev_id', how='left')\n",
    "demo = allRevAttackOnlyGrouped.loc[:,'english_first_language':].div(boolColsGrouped.loc[:,'english_first_language':])\n",
    "totalAnnotators = boolCols.groupby('rev_id', as_index=False).count()['attack']\n",
    "attack = boolColsGrouped['attack'].div(totalAnnotators).to_frame('pctAttack')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the max demographic percentage that advocated for attack in each row and add it to the attack\n",
    "# dataframe. Create an attack column for the target labels and flip any rows meeting the criteria\n",
    "# to True. Insert the rev_id column into the attack frame \n",
    "demoMax = demo.loc[:,'english_first_language':].max(axis = 1)\n",
    "attack.insert(1,'demoMax',demoMax)\n",
    "attack['attack'] = False\n",
    "attack.loc[(attack['pctAttack'] >= .5) | (attack['demoMax'] > .5), 'attack'] = True\n",
    "attack.loc[attack['pctAttack'] <.25,'attack'] = False\n",
    "attack.insert(0,'rev_id',boolColsGrouped['rev_id'])\n",
    "labels = attack.drop(columns=['demoMax', 'pctAttack'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the labels data frame by dropping irrelevant columns from the attack frame and merge the\n",
    "# labels into the comments dataframe to complete labeling all comments\n",
    "labels = attack.drop(columns=['demoMax', 'pctAttack'])\n",
    "comments = pd.merge(comments, labels, on='rev_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Cleaning the data\n",
    "In addition to the cleaning necessary to create the labels, there is cleaning done on the comment text as well:\n",
    " - Remove newline and tab tokens\n",
    " - Split into test and train groups\n",
    " - Remove stop words from the word ngrams\n",
    " - Convert all characters to lowercase\n",
    " - Strip all accents\n",
    " - Change the comments into vectors necessary for most classifiers\n",
    " - Encode the labels for use by the classifiers\n",
    "     - scored for rarity and frequency (tfidf)\n",
    "Other methods I tried included setting maximum and minimum document frequency, however, these are made a bit redundant by removing stop words and setting max_feature limits respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove newline and tab tokens\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and encode the training data\n",
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "    comments.comment, comments.attack, test_size=.33,random_state=42)\n",
    "\n",
    "encode = LabelEncoder()\n",
    "y_train = encode.fit_transform(y_train)\n",
    "y_test = encode.fit_transform(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Features, Methods and Parameters, Oh my\n",
    "#### 3.1 Features\n",
    "The features are pretty basic with a blend of word and character n-grams. I tried making a couple features such as exclamation mark to sentence ending punctuation ratio, as well as, upper case letter proportion, to attempt to capture times when people are figuratively yelling. However, they didn't make much of a difference so I left them out.\n",
    "\n",
    "#### 3.2 Results, the output on average looks like this\n",
    "\n",
    "| Method | Label | Precision | Recall | F1-Score | Support |\n",
    "| ----------- | ----------- | ----------- | ----------- | ----------- | ----------- |\n",
    "| Stochastic Gradient Descent | Not Attack | .92 | .97 | .94 | 30,754 |\n",
    "|  | Attack | .84 | .66 | 74 | 7,482 |\n",
    "|  | Weighted Avg. | .91 | .91 | .90 | 38,236 |\n",
    "\n",
    "#### 3.3 Fine Tuning\n",
    "I took a look at altering nearly every parameter in the documentation, as well as max_feature numbers from 5,000 to 100,000. The biggest difference maker for the SGD model was switching the loss to 'modified_huber' which is ironic given that huber loss is for regression, but I suppose that is what makes it modified. I was able to improve SGD by 2% overall weighted average by increasing attack recall by 16% while attack accuracy reduced by 8% for a net 8% gain on attack while on not attack precision went up 3% while recall only lost 1%.\n",
    "\n",
    "I used a mixture of BayesSearchCV from the skopt module (scikit optimize), and RandomSearchCV to quickly get a better idea of what features and value areas looked best then finished it out with a couple of large and long GridSearchCVs to find the best combos. I tried optimizing for precision, recall, and f1-score independently and as might be expected found that precision and recall often offer a tradeoff so in the end optimizing for f1 at least smoothed the trade to get the two values closer to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the parameter grid, I kept it separate for ease in tweaking values:\n",
    "\n",
    "parameterGrid = dict(\n",
    "    features__word__max_features=[10000],\n",
    "    features__word__ngram_range=[(1,2)],\n",
    "    features__word__lowercase=[True],\n",
    "    features__word__stop_words=['english'],\n",
    "    features__word__strip_accents=['unicode'],\n",
    "    \n",
    "    features__char__max_features=[25000],\n",
    "    features__char__ngram_range=[(2,3)],\n",
    "    features__char__lowercase=[True],\n",
    "    features__char__strip_accents=['unicode'],\n",
    "    clf__loss=['modified_huber'],\n",
    "    clf__alpha=[.0001],\n",
    "    clf__learning_rate=['optimal'],\n",
    "    clf__eta0=[.001]\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup classifier\n",
    "clf = SGDClassifier(verbose = 51) #Verbosity over 50 prints the entire log as it is fitted\n",
    "wVector = TfidfVectorizer(analyzer='word')\n",
    "cVector = TfidfVectorizer(analyzer='char')\n",
    "fUnion = FeatureUnion([(\"word\", wVector), (\"char\", cVector)])\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('features', fUnion),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=parameterGrid, n_jobs=6, pre_dispatch=4,\n",
    "                            verbose=51,cv=3, scoring='f1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:   51.1s\n",
      "[Parallel(n_jobs=6)]: Done   3 out of   3 | elapsed:   51.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   3 out of   3 | elapsed:   51.4s finished\n",
      "-- Epoch 1\n",
      "Norm: 39.67, NNZs: 34254, Bias: -1.381699, T: 77628, Avg. loss: 0.786204\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31.83, NNZs: 34639, Bias: -1.158743, T: 155256, Avg. loss: 0.269599\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 29.88, NNZs: 34729, Bias: -1.079704, T: 232884, Avg. loss: 0.245773\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 29.02, NNZs: 34749, Bias: -1.045399, T: 310512, Avg. loss: 0.237410\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 28.55, NNZs: 34768, Bias: -1.036023, T: 388140, Avg. loss: 0.232991\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 28.24, NNZs: 34770, Bias: -1.025659, T: 465768, Avg. loss: 0.230301\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 28.08, NNZs: 34775, Bias: -1.021098, T: 543396, Avg. loss: 0.228061\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 27.91, NNZs: 34776, Bias: -1.013780, T: 621024, Avg. loss: 0.226311\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 27.80, NNZs: 34777, Bias: -1.016226, T: 698652, Avg. loss: 0.225379\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 27.70, NNZs: 34777, Bias: -1.008953, T: 776280, Avg. loss: 0.224665\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 27.63, NNZs: 34796, Bias: -1.008888, T: 853908, Avg. loss: 0.223796\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 27.59, NNZs: 34796, Bias: -1.003527, T: 931536, Avg. loss: 0.223228\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 27.54, NNZs: 34796, Bias: -1.003688, T: 1009164, Avg. loss: 0.222801\n",
      "Total training time: 0.97 seconds.\n",
      "Convergence after 13 epochs took 0.97 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('features',\n",
       "                                        FeatureUnion(transformer_list=[('word',\n",
       "                                                                        TfidfVectorizer()),\n",
       "                                                                       ('char',\n",
       "                                                                        TfidfVectorizer(analyzer='char'))])),\n",
       "                                       ('clf', SGDClassifier(verbose=51))]),\n",
       "             n_jobs=6,\n",
       "             param_grid={'clf__alpha': [0.0001], 'clf__eta0': [0.001],\n",
       "                         'clf__learning_rate': ['optimal'],\n",
       "                         'clf__loss': ['modified_huber'],\n",
       "                         'features__char__lowercase':...\n",
       "                         'features__char__max_features': [25000],\n",
       "                         'features__char__ngram_range': [(2, 3)],\n",
       "                         'features__char__strip_accents': ['unicode'],\n",
       "                         'features__word__lowercase': [True],\n",
       "                         'features__word__max_features': [10000],\n",
       "                         'features__word__ngram_range': [(1, 2)],\n",
       "                         'features__word__stop_words': ['english'],\n",
       "                         'features__word__strip_accents': ['unicode']},\n",
       "             pre_dispatch=4, scoring='f1', verbose=51)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.94     30754\n",
      "           1       0.86      0.63      0.73      7482\n",
      "\n",
      "    accuracy                           0.91     38236\n",
      "   macro avg       0.89      0.80      0.84     38236\n",
      "weighted avg       0.91      0.91      0.90     38236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "y_valid_pred = grid_search.best_estimator_.predict(X_test)\n",
    "met = classification_report(y_test, y_valid_pred)\n",
    "print(met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30001   753]\n",
      " [ 2755  4727]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix: Y-axis is what was predicted by the model, X-axis is what it should be\n",
    "conf_mat = confusion_matrix(y_test, y_valid_pred)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "\tclf__alpha: 0.0001\n",
      "\tclf__eta0: 0.001\n",
      "\tclf__learning_rate: 'optimal'\n",
      "\tclf__loss: 'modified_huber'\n",
      "\tfeatures__char__lowercase: True\n",
      "\tfeatures__char__max_features: 25000\n",
      "\tfeatures__char__ngram_range: (2, 3)\n",
      "\tfeatures__char__strip_accents: 'unicode'\n",
      "\tfeatures__word__lowercase: True\n",
      "\tfeatures__word__max_features: 10000\n",
      "\tfeatures__word__ngram_range: (1, 2)\n",
      "\tfeatures__word__stop_words: 'english'\n",
      "\tfeatures__word__strip_accents: 'unicode'\n"
     ]
    }
   ],
   "source": [
    "# Lists best parameters from the grid search, borrowed from lecture code:\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameterGrid.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
